{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tRI_FbVsYL8"
      },
      "source": [
        "## Import Keras and Packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri4b9T0zsYL9"
      },
      "source": [
        "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "N8F_lk-DsYL9"
      },
      "outputs": [],
      "source": [
        "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
        "# If you run this notebook on a different environment, e.g. your desktop, you may need to uncomment and install certain libraries.\n",
        "\n",
        "#!pip install numpy==1.21.4\n",
        "#!pip install pandas==1.3.4\n",
        "#!pip install keras==2.1.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Fbu6skphsYL-",
        "outputId": "eff48987-e86c-466e-e3c9-26f7afe8240f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1jdk6aisYL_"
      },
      "source": [
        "When working with convolutional neural networks in particular, we will need additional packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "WKLP9YYVsYMA"
      },
      "outputs": [],
      "source": [
        "from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
        "from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
        "from keras.layers import Flatten # to flatten data for fully connected layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFAoHbhEsYMB"
      },
      "source": [
        "<a id='item42'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiKresTgsYMB"
      },
      "source": [
        "## Convolutional Layer with One set of convolutional and pooling layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "VRJMdwqPsYMB",
        "outputId": "2f84ca07-8eb7-4950-d712-18ef7fb8071b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# import data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96bPGYq_sYMB"
      },
      "source": [
        "Let's normalize the pixel values to be between 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "HowM1wgbsYMB"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255 # normalize training data\n",
        "X_test = X_test / 255 # normalize test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7utKodDYsYMB"
      },
      "source": [
        "Next, let's convert the target variable into binary categories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "7dmHNd29sYMC"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1] # number of categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHHNlV3PsYMC"
      },
      "source": [
        "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "n_qGXcYXsYMC"
      },
      "outputs": [],
      "source": [
        "def convolutional_model():\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9MWSXPjsYMC"
      },
      "source": [
        "Finally, let's call the function to create the model, and then let's train it and evaluate it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "9d00zzJosYMC",
        "outputId": "d6f1f8b1-7773-4ca6-a970-48855498edef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3014: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-07 21:30:33.910875: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
            "2023-08-07 21:30:33.915953: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494065000 Hz\n",
            "2023-08-07 21:30:33.916590: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e621f55bc0 executing computations on platform Host. Devices:\n",
            "2023-08-07 21:30:33.916639: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2023-08-07 21:30:34.017897: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " - 36s - loss: 0.2960 - acc: 0.9151 - val_loss: 0.1041 - val_acc: 0.9694\n",
            "Epoch 2/10\n",
            " - 34s - loss: 0.0877 - acc: 0.9744 - val_loss: 0.0618 - val_acc: 0.9798\n",
            "Epoch 3/10\n",
            " - 35s - loss: 0.0584 - acc: 0.9828 - val_loss: 0.0528 - val_acc: 0.9818\n",
            "Epoch 4/10\n",
            " - 34s - loss: 0.0451 - acc: 0.9868 - val_loss: 0.0440 - val_acc: 0.9859\n",
            "Epoch 5/10\n",
            " - 35s - loss: 0.0375 - acc: 0.9887 - val_loss: 0.0450 - val_acc: 0.9853\n",
            "Epoch 6/10\n",
            " - 34s - loss: 0.0307 - acc: 0.9907 - val_loss: 0.0377 - val_acc: 0.9874\n",
            "Epoch 7/10\n",
            " - 35s - loss: 0.0264 - acc: 0.9918 - val_loss: 0.0387 - val_acc: 0.9859\n",
            "Epoch 8/10\n",
            " - 34s - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0336 - val_acc: 0.9888\n",
            "Epoch 9/10\n",
            " - 34s - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0353 - val_acc: 0.9893\n",
            "Epoch 10/10\n",
            " - 33s - loss: 0.0150 - acc: 0.9955 - val_loss: 0.0336 - val_acc: 0.9897\n",
            "Accuracy: 0.9897 \n",
            " Error: 1.0300000000000011\n"
          ]
        }
      ],
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NONI4w6sYMC"
      },
      "source": [
        "------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr6Djm23sYMC"
      },
      "source": [
        "<a id='item43'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfm4381ysYMD"
      },
      "source": [
        "## Convolutional Layer with two sets of convolutional and pooling layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS9-BQcosYMD"
      },
      "source": [
        "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "6IMtfcPPsYMD"
      },
      "outputs": [],
      "source": [
        "def convolutional_model():\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qtUNiFfsYMD"
      },
      "source": [
        "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "S8Tbm1UVsYMD",
        "outputId": "e0d3d4ef-e850-401a-a5e1-5b354924b9d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 36s - loss: 0.5025 - acc: 0.8594 - val_loss: 0.1585 - val_acc: 0.9535\n",
            "Epoch 2/10\n",
            " - 36s - loss: 0.1364 - acc: 0.9590 - val_loss: 0.0959 - val_acc: 0.9708\n",
            "Epoch 3/10\n",
            " - 35s - loss: 0.0929 - acc: 0.9716 - val_loss: 0.0713 - val_acc: 0.9780\n",
            "Epoch 4/10\n",
            " - 36s - loss: 0.0757 - acc: 0.9772 - val_loss: 0.0623 - val_acc: 0.9796\n",
            "Epoch 5/10\n",
            " - 36s - loss: 0.0629 - acc: 0.9807 - val_loss: 0.0590 - val_acc: 0.9809\n",
            "Epoch 6/10\n",
            " - 35s - loss: 0.0547 - acc: 0.9834 - val_loss: 0.0518 - val_acc: 0.9830\n",
            "Epoch 7/10\n",
            " - 36s - loss: 0.0491 - acc: 0.9852 - val_loss: 0.0480 - val_acc: 0.9854\n",
            "Epoch 8/10\n",
            " - 35s - loss: 0.0447 - acc: 0.9864 - val_loss: 0.0455 - val_acc: 0.9849\n",
            "Epoch 9/10\n",
            " - 36s - loss: 0.0408 - acc: 0.9875 - val_loss: 0.0466 - val_acc: 0.9848\n",
            "Epoch 10/10\n",
            " - 35s - loss: 0.0372 - acc: 0.9892 - val_loss: 0.0458 - val_acc: 0.9842\n",
            "Accuracy: 0.9842 \n",
            " Error: 1.5799999999999983\n"
          ]
        }
      ],
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}